<!DOCTYPE html>
<html>

<head>
    <title>Sadie Garner</title>

    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta charset="utf-8">
    <meta name="author" content="Amy Pegram, 1825142">
    <meta name="description" content="Blog: `+ BlogTitle + `">
    <link rel="icon" href="/WSOA3028A_1825142/Logo.png" type="image/png">

    <meta property="og:title" content="Sadie Garner" />
    <meta property="og:type" content="website" />
    <meta property="og:url" content="https://vividcurlyfry.github.io/WSOA3028A_1825142/Blogs/Blog9-Tweet.html" />
    <meta property="og:image" content="WSOA3028A_1825142/Logo.png" />
    <meta property="og:description" content="Blog: Analysing a Tweet">

    <link href="/WSOA3028A_1825142/css/stylesheet.css" rel="stylesheet">
    <script src="/WSOA3028A_1825142/js/blogtemplate.js" async></script>
    <script src="/WSOA3028A_1825142/js/navbar.js" async></script>
</head>

<body
    onload="LoadBlogPost('Analysing a Tweet','<p><img class= &quot pictureRow &quot src=&quot /WSOA3028A_1825142/Theory/Tweet.png &quot alt=&quot A Tweet that describes a girls experience with taking a passport photo and the software telling her that her mouth was open even though it was not. &quot height=80%> </p><p>When I saw this Tweet, I was immediately excited to talk about it. I have previously written an essay on the topic of Facial Recognition in terms on the ACM code of ethics. The ACM code of ethics refers to the Association for Computing Machinery Code of Ethics. These are a list of “rules” that software engineers should follow when designing software. When it comes to facial recognition software, there is a huge issue regarding race.</p><h3>What are the types of Facial Recognition Software?</h3><p>Facial Recognition refers to technology that identifies faces. It is a type of biometric software. There are two ways that faces can be recognised. The first being feature based. The other is a holistic approach. This would look at the entire face and, based on the position of features on the face, identify the person. In this Tweet, I think the algorithm is using a holistic approach, as it may be calculating how large the mouth “should” be in proportion to the face. I have no idea how this works though. So I may be completely wrong. It’s a (semi?)-educated guess.</p><p>There are a few limitations when it comes to the identification of faces. If the method that a picture is not standardised, there may be issues such as lighting and face angle. The issue here is that the way the photo is taken IS standardised. The person is facing forward and the lighting is good. There is a clear discrepancy between what the “issue” seems to be. You can see that this person’s mouth is closed, and there seems to be an error saying their mouth isn’t closed. There is definitely an error in of the facial recognition algorithm.</p><h3>Issues With Race And Facial Recognition</h3><p>There is a major issue with facial recognition software being racist. Searching “Facial Recognition Software Racist” on Google returns “About 1 390 000 results”. Here are some facts from a study performed by the  US National Institute of Standards and Technology (NIST) popular facial recognition software [1]:</p> <p style = &quot margin: 0; &quot> &quot <ol style= &quot list-style-position: inside; &quot><li>For one-to-one matching, most systems had a higher rate of false positive matches for Asian and African-American faces over Caucasian faces, sometimes by a factor of 10 or even 100. In other words, they were more likely to find a match when there wasn’t one.</li><li>This changed for face recognition algorithms developed in Asian countries, which produced very little difference in false positives between Asian and Caucasian faces.</li><li>Algorithms developed in the US were all consistently bad at matching Asian, African-American, and Native American faces. Native Americans suffered the highest false positive rates.</li><li>One-to-many matching, systems had the worst false positive rates for African-American women, which puts this population at the highest risk for being falsely accused of a crime.</li></ol> &quot </p><p>The statements above highlight the issue with facial recognition in America. Minorities in the country are more likely to be falsely identified by facial recognition technology. This is due to the fact that white engineers have developed these technologies to identify white faces [2]. This means the technology is not suited to identify faces accurately that are not white. As seen above, technology developed in Asian countries does not have an issue correctly identifying Asian faces.</p><p>According to the ACM Code of ethics, software must be developed to ”Be fair and take action not to discriminate.” Therefore, these softwares are clearly breaking the ACM code of ethics. The racial discrimination taking place with technology needs to be stopped as it is unethical.</p>', '<p><cite>[1] K. Hao, &quot A US government study confirms most face recognition systems are racist,&quot 20 December 2019. [Online]. Available: <a href= &quot  https://www.technologyreview.com/2019/12/20/79/ai-face-recognition-racist-us-government-nist-study/ &quot>  https://www.technologyreview.com/2019/12/20/79/ai-face-recognition-racist-us-government-nist-study/</a> [Accessed 05 06 2020].</cite></p><p><cite> [2] A. Breland, &quot How white engineers built racist code – and why its dangerous for black people,&quot 4 December 2017. [Online]. Available: <a href= &quot  https://www.theguardian.com/technology/2017/dec/04/racist-facial-recognition-white-coders-black-people-police &quot> https://www.theguardian.com/technology/2017/dec/04/racist-facial-recognition-white-coders-black-people-police</a> [Accessed 05 06 2020].</cite></p>'); generateNav()">
    <nav></nav>
</body>

</html>